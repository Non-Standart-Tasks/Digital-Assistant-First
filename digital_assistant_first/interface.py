# –ò–º–ø–æ—Ä—Ç—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
import logging
import json
import asyncio
import pandas as pd
import streamlit as st

# –ò–º–ø–æ—Ä—Ç—ã —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
from langchain_core.prompts import ChatPromptTemplate
from digital_assistant_first.utils.check_serp_response import APIKeyManager
from digital_assistant_first.utils.logging import setup_logging, log_api_call
from digital_assistant_first.internet_search import search_shopping, search_places
import pydeck as pdk

# –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from digital_assistant_first.telegram_system.telegram_rag import EnhancedRAGSystem
from digital_assistant_first.telegram_system.telegram_data_initializer import (
    TelegramManager,
)
from digital_assistant_first.telegram_system.telegram_initialization import (
    fetch_telegram_data,
)
from digital_assistant_first.utils.aviasales_parser import AviasalesHandler
from digital_assistant_first.geo_system.two_gis import fetch_2gis_data
from digital_assistant_first.offergen.agent import validation_agent
from digital_assistant_first.offergen.utils import get_system_prompt_for_offers
from streamlit_app import initialize_model
from digital_assistant_first.yndx_system.restaurant_context import fetch_yndx_context
from digital_assistant_first.utils.link_checker import link_checker, corrector
from digital_assistant_first.utils.database import (
    init_db, 
    insert_chat_history_return_id, 
    update_chat_history_rating_by_id, 
    get_chat_record_by_id
)

from dotenv import load_dotenv

load_dotenv()

logger = setup_logging(logging_path="logs/digital_assistant.log")
serpapi_key_manager = APIKeyManager(path_to_file="api_keys_status.csv")
init_db()

async def model_response_generator(model, config):
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ –∏ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ."""
    user_input = st.session_state["messages"][-1]["content"]
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ message_history
    message_history = ""
    if "messages" in st.session_state and len(st.session_state["messages"]) > 1:
        history_messages = [
            f"{msg['role']}: {msg['content']}"
            for msg in st.session_state["messages"]
            if msg.get("role") != "system"
        ]
        history_size = int(config.get("history_size", 0))
        if history_size:
            history_messages = history_messages[-history_size:]
        message_history = "\n".join(history_messages)

    # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    tasks = []
    
    # –ó–∞–¥–∞—á–∞ –¥–ª—è Aviasales
    aviasales_tool = AviasalesHandler()
    tasks.append(aviasales_tool.aviasales_request(model, config, user_input))
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    shopping_res = ""
    internet_res = ""
    links = ""
    telegram_context = ""
    table_data = []
    pydeck_data = []
    
    # –ó–∞–¥–∞—á–∏ –¥–ª—è –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–æ–∏—Å–∫–∞
    if config.get("internet_search", False):
        async def fetch_internet_data():
            _, serpapi_key = serpapi_key_manager.get_best_api_key()
            shopping = await search_shopping(user_input, serpapi_key)
            internet, links_data, _ = await search_places(user_input, serpapi_key)
            return shopping, internet, links_data
        
        tasks.append(fetch_internet_data())
    
    # –ó–∞–¥–∞—á–∞ –¥–ª—è Telegram
    if config.get("telegram_enabled", False):
        async def fetch_telegram_data_async():
            telegram_manager = TelegramManager()
            rag_system = EnhancedRAGSystem(
                data_file="data/telegram_messages.json", index_directory="data/"
            )
            return await fetch_telegram_data(user_input, rag_system, k=50)
        
        tasks.append(fetch_telegram_data_async())
    
    # –ó–∞–¥–∞—á–∞ –¥–ª—è 2Gis
    if config.get("mode") == "2Gis":
        tasks.append(fetch_2gis_data(user_input, config))
    
    try:
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        result_index = 0
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç Aviasales
        tickets_need = results[result_index] if not isinstance(results[result_index], Exception) else {"response": "false"}
        result_index += 1
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–æ–∏—Å–∫–∞
        if config.get("internet_search", False):
            if not isinstance(results[result_index], Exception):
                shopping_res, internet_res, links = results[result_index]
            result_index += 1
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã Telegram
        if config.get("telegram_enabled", False):
            if not isinstance(results[result_index], Exception):
                telegram_context = results[result_index]
            result_index += 1
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã 2Gis
        if config.get("mode") == "2Gis":
            if not isinstance(results[result_index], Exception):
                table_data, pydeck_data = results[result_index]
            result_index += 1
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è Aviasales
        aviasales_url = ""
        if tickets_need.get("response", "").lower() == "true":
            aviasales_url = aviasales_tool.construct_aviasales_url(
                tickets_need["departure_city"],
                tickets_need["destination"],
                tickets_need["start_date"],
                tickets_need["end_date"],
                tickets_need["passengers"],
                tickets_need.get("travel_class", ""),
            )
            aviasales_flight_info = aviasales_tool.get_info_aviasales_url(aviasales_url=aviasales_url, user_input=user_input)
            else:
                aviasales_url = ""
                aviasales_flight_info = ""
        else:
            aviasales_url = ""
            aviasales_flight_info = ""
            
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        system_prompt_template = config["system_prompt"]
        formatted_prompt = system_prompt_template.format(
            context=message_history,
            internet_res=internet_res,
            links=links,
            shopping_res=shopping_res,
            telegram_context=telegram_context,
            # yndx_restaurants=restaurants_prompt,
            aviasales_flight_info=aviasales_flight_info,
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏
        prompt_template = ChatPromptTemplate.from_messages(
            [
                ("system", formatted_prompt),
                ("human", "User query: {input}\nAdditional context: {context}"),
            ]
        )
        messages = prompt_template.format(input=user_input, context="")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é —Å —è–≤–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–º streaming
        response = model.invoke(messages, stream=False)
        
        if hasattr(response, "content"):
            answer = response.content
        elif hasattr(response, "message"):
            answer = response.message.content
        else:
            answer = str(response)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è —Å—Å—ã–ª–æ–∫
        link_statuses = await link_checker.run(answer)
        
        if link_statuses.data.links:
            some_link_is_invalid = any(
                not link.status for link in link_statuses.data.links
            )
            if some_link_is_invalid:
                corrected_answer = await corrector.run(answer, deps=link_statuses.data.links)
                answer = corrected_answer.data
        
        log_api_call(
            logger=logger,
            source=f"LLM ({config['Model']})",
            request=user_input,
            response=answer,
        )
        
        return {
            "answer": answer,
            "aviasales_link": aviasales_url,
            "table_data": table_data or [],
            "pydeck_data": pydeck_data or [],
        }
        
    except Exception as e:
        logger.error(f"Error in model_response_generator: {str(e)}", exc_info=True)
        log_api_call(
            logger=logger,
            source=f"LLM ({config['Model']})",
            request=user_input,
            response="",
            error=str(e),
        )
        raise

def offers_mode_interface(config):
    """
    –†–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ñ—Ñ–µ—Ä–æ–≤. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º nest_asyncio,
    –≤—Ä—É—á–Ω—É—é —Å–æ–∑–¥–∞—ë–º event loop –¥–ª—è –≤—ã–∑–æ–≤–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ validation_agent.
    """
    st.subheader("–†–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ñ—Ñ–µ—Ä–æ–≤ VTB Family")
    if "messages_offers" not in st.session_state:
        st.session_state["messages_offers"] = []
    user_input = st.chat_input("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ñ—Ñ–µ—Ä–æ–≤...")
    if user_input:
        st.session_state["messages_offers"].append(
            {"role": "user", "content": user_input}
        )
        with st.chat_message("user"):
            st.markdown(user_input)
        try:
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            validation_result = loop.run_until_complete(
                validation_agent.run(user_input)
            ).data
            if validation_result.number_of_offers_to_generate < 1:
                validation_result.number_of_offers_to_generate = 10
            system_prompt = get_system_prompt_for_offers(validation_result, user_input)
            if system_prompt == "No relevant offers were found for the search request.":
                with st.chat_message("assistant"):
                    st.warning("–û—Ñ—Ñ–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —É—Ç–æ—á–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å.")
                return
            model = initialize_model(config)
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_input},
            ]
            response = model.invoke(messages, stream=True)
            response_text = ""
            with st.chat_message("assistant"):
                response_placeholder = st.empty()
                for chunk in response:
                    if isinstance(chunk, tuple) and len(chunk) == 2:
                        key, value = chunk
                        if key == "content":
                            response_text += value
                            response_placeholder.markdown(response_text)
        except Exception as e:
            st.error(f"Error in offers generation: {str(e)}")

async def handle_user_input(model, config, prompt):
    """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–≤–æ–¥ –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞."""
    if prompt:
        st.session_state["messages"].append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            response_text = ""
            response = await model_response_generator(model, config)
            response_text += response["answer"]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–∞ aviasales_link
            if "aviasales_link" in response:
                aviasales_link = response["aviasales_link"]
                # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ–ø—É—Å—Ç–æ–µ, –¥–æ–±–∞–≤–ª—è–µ–º —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º, –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ (–æ–±—ã—á–Ω–æ –ø—É—Å—Ç–æ–µ)
                if aviasales_link and aviasales_link.strip():
                    response_text += f"\n\n### –î–∞–Ω–Ω—ã–µ –∏–∑ –ê–≤–∏–∞—Å–µ–π–ª—Å \n **–°—Å—ã–ª–∫–∞** - {aviasales_link}"
                else:
                    response_text += f"\n\n{aviasales_link}"

            if config["mode"] == "2Gis":

                response_text += f"\n\n### –î–∞–Ω–Ω—ã–µ –∏–∑ 2–ì–∏—Å"
                if "table_data" in response:
                    df = pd.DataFrame(response["table_data"])
                    st.dataframe(df)  # –ö—Ä–∞—Å–∏–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
                else:
                    st.warning("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

                # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ PyDeck –∫–∞—Ä—Ç—ã
                if "pydeck_data" in response:
                    df_pydeck = pd.DataFrame(response["pydeck_data"])
                    st.subheader("–ö–∞—Ä—Ç–∞")
                    st.pydeck_chart(
                        pdk.Deck(
                            map_style=None,
                            initial_view_state=pdk.ViewState(
                                latitude=df_pydeck["lat"].mean(),
                                longitude=df_pydeck["lon"].mean(),
                                zoom=13,
                            ),
                            layers=[
                                pdk.Layer(
                                    "ScatterplotLayer",
                                    data=df_pydeck,
                                    get_position="[lon, lat]",
                                    get_radius=30,
                                    get_fill_color=[255, 0, 0],
                                    pickable=True,
                                )
                            ],
                            tooltip={
                                "html": "<b>{name}</b>",
                                "style": {"color": "white"},
                            },
                        )
                    )
                else:
                    st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ—á–µ–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ PyDeck-–∫–∞—Ä—Ç–µ.")

            # Update the response placeholder for each chunk, regardless of mode
            response_placeholder.markdown(response_text)

            st.session_state["messages"].append(
                {"role": "assistant", "content": response_text, "question": prompt}
            )
            
            st.markdown("### –û—Ü–µ–Ω–∏—Ç–µ –æ—Ç–≤–µ—Ç:")
            col1, col2 = st.columns(2)
            if col1.button("üëç", key=f"thumbs_up_{len(st.session_state['messages'])}"):
                st.success("–í—ã –ø–æ—Å—Ç–∞–≤–∏–ª–∏ üëç")
            if col2.button("üëé", key=f"thumbs_down_{len(st.session_state['messages'])}"):
                st.error("–í—ã –ø–æ—Å—Ç–∞–≤–∏–ª–∏ üëé")  

            record_id = insert_chat_history_return_id(
            user_query=prompt,
            model_response=response_text,
            mode=config["mode"],
            rating=None
            )

            # –í —Å–∞–º–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —Ç–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω–∏–º record_id –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ª–∞–π–∫–∞/–¥–∏–∑–ª–∞–π–∫–∞
            st.session_state["messages"][-1]["record_id"] = record_id

def init_message_history(template_prompt):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —á–∞—Ç–∞."""
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
        with st.chat_message("System"):
            st.markdown(template_prompt)


def display_chat_history():
    """–û—Ç–æ–±—Ä–∞–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏ (–≤–∫–ª—é—á–∞—è –∫–Ω–æ–ø–∫–∏ —Ä–µ–π—Ç–∏–Ω–≥–∞ –¥–ª—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞)."""
    for i, message in enumerate(st.session_state["messages"]):
        with st.chat_message(message["role"]):
            # –ï—Å–ª–∏ –±—ã–ª–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ "question", –ø–æ–∫–∞–∂–µ–º –µ–≥–æ –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            if "question" in message:
                st.markdown(f"**–í–æ–ø—Ä–æ—Å**: {message['question']}")

            # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            st.markdown(message["content"])

            # –ï—Å–ª–∏ —ç—Ç–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∏ –µ—Å—Ç—å record_id, —Ä–∏—Å—É–µ–º –∫–Ω–æ–ø–∫–∏ —Ä–µ–π—Ç–∏–Ω–≥–∞
            if message["role"] == "assistant":
                record_id = message.get("record_id")
                if record_id:
                    col1, col2 = st.columns(2)

                    if col1.button("üëç", key=f"thumbs_up_{i}"):
                        update_chat_history_rating_by_id(record_id, "+")
                        st.session_state["last_rating_action"] = f"–ü–æ—Å—Ç–∞–≤–∏–ª–∏ –ª–∞–π–∫ –¥–ª—è –∑–∞–ø–∏—Å–∏ ID={record_id}"
                        st.rerun()

                    if col2.button("üëé", key=f"thumbs_down_{i}"):
                        update_chat_history_rating_by_id(record_id, "-")
                        st.session_state["last_rating_action"] = f"–ü–æ—Å—Ç–∞–≤–∏–ª–∏ –¥–∏–∑–ª–∞–π–∫ –¥–ª—è –∑–∞–ø–∏—Å–∏ ID={record_id}"
                        st.rerun()

    # –ü–æ—Å–ª–µ —Ä–µ—Ä–µ–Ω–¥–µ—Ä–∞ –ø–æ–∫–∞–∂–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è
    if "last_rating_action" in st.session_state:
        st.info(st.session_state["last_rating_action"])
